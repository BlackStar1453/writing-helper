/**
 * hasNotEngine-ultra-fast é›†æˆæµ‹è¯•
 * 
 * ä½¿ç”¨æ¨¡æ‹Ÿçš„ OpenAI å®¢æˆ·ç«¯è¿›è¡Œå®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•
 */

import { NextRequest } from 'next/server';
import { POST } from '../src/app/api/hasNotEngine-ultra-fast/route';

// æ¨¡æ‹Ÿ OpenAI æ¨¡å—
jest.mock('openai', () => {
  return {
    __esModule: true,
    default: jest.fn().mockImplementation(() => ({
      chat: {
        completions: {
          create: jest.fn().mockImplementation(async (params) => {
            // æ¨¡æ‹Ÿæµå¼å“åº”
            if (params.stream) {
              return createMockStream();
            }
            // æ¨¡æ‹Ÿéæµå¼å“åº”
            return {
              choices: [{
                message: {
                  content: 'This is a test response from mocked OpenAI'
                }
              }],
              usage: {
                prompt_tokens: 10,
                completion_tokens: 8,
                total_tokens: 18
              }
            };
          })
        }
      }
    }))
  };
});

// æ¨¡æ‹Ÿè®¤è¯æ¨¡å—
jest.mock('../lib/auth', () => ({
  fastVerifyAuth: jest.fn().mockResolvedValue({
    success: true,
    user: {
      id: '1675524b-820b-478f-b841-f94aaffac413',
      email: '1519235462@qq.com',
      plan: 'Premium'
    }
  })
}));

// æ¨¡æ‹Ÿä½¿ç”¨é‡æ£€æŸ¥
jest.mock('../lib/usage-ultra-fast', () => ({
  checkAndUpdateUsageUltraFast: jest.fn().mockResolvedValue({
    success: true,
    canProceed: true,
    usage: {
      used: 5,
      limit: 1000,
      remaining: 995
    }
  })
}));

// åˆ›å»ºæ¨¡æ‹Ÿçš„æµå¼å“åº”
function createMockStream() {
  const chunks = [
    { choices: [{ delta: { content: 'Hello' } }] },
    { choices: [{ delta: { content: ' there!' } }] },
    { choices: [{ delta: { content: ' How' } }] },
    { choices: [{ delta: { content: ' can' } }] },
    { choices: [{ delta: { content: ' I' } }] },
    { choices: [{ delta: { content: ' help' } }] },
    { choices: [{ delta: { content: ' you?' } }] },
    { choices: [{ finish_reason: 'stop' }] }
  ];

  let index = 0;
  
  return {
    [Symbol.asyncIterator]: async function* () {
      for (const chunk of chunks) {
        // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        await new Promise(resolve => setTimeout(resolve, 50));
        yield chunk;
      }
    }
  };
}

// åˆ›å»ºæµ‹è¯•è¯·æ±‚çš„è¾…åŠ©å‡½æ•°
function createTestRequest(body: any, headers: Record<string, string> = {}): NextRequest {
  const url = 'http://localhost:3000/api/hasNotEngine-ultra-fast';
  const request = new NextRequest(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': 'Bearer test-token',
      ...headers
    },
    body: JSON.stringify(body)
  });
  return request;
}

describe('hasNotEngine-ultra-fast é›†æˆæµ‹è¯•', () => {
  
  beforeEach(() => {
    jest.clearAllMocks();
    console.log('ğŸ§ª å¼€å§‹é›†æˆæµ‹è¯•');
  });

  describe('å®Œæ•´è¯·æ±‚æµç¨‹æµ‹è¯•', () => {
    test('åº”è¯¥æˆåŠŸå¤„ç†æœ‰æ•ˆçš„èŠå¤©è¯·æ±‚', async () => {
      const request = createTestRequest({
        query: 'Hello, how are you?',
        model: 'gpt-4o-mini'
      });

      const response = await POST(request);

      // éªŒè¯å“åº”çŠ¶æ€å’Œå¤´éƒ¨
      expect(response.status).toBe(200);
      expect(response.headers.get('Content-Type')).toBe('text/event-stream');
      expect(response.headers.get('Cache-Control')).toBe('no-cache');
      expect(response.headers.get('Connection')).toBe('keep-alive');

      console.log('âœ… å“åº”å¤´éªŒè¯é€šè¿‡');

      // è¯»å–æµå¼å“åº”
      const reader = response.body?.getReader();
      expect(reader).toBeDefined();

      if (reader) {
        const chunks: string[] = [];
        let done = false;

        while (!done) {
          const { value, done: streamDone } = await reader.read();
          done = streamDone;

          if (value) {
            const chunk = new TextDecoder().decode(value);
            chunks.push(chunk);
          }
        }

        const fullResponse = chunks.join('');
        console.log('ğŸ“¡ æ¥æ”¶åˆ°çš„æµå¼å“åº”:', fullResponse.substring(0, 200) + '...');

        // éªŒè¯å“åº”åŒ…å«é¢„æœŸçš„ SSE æ ¼å¼
        expect(fullResponse).toContain('data:');
        expect(fullResponse).toContain('type');

        // éªŒè¯åŒ…å«æ€§èƒ½æ•°æ®
        expect(fullResponse).toContain('performance');
        expect(fullResponse).toContain('serverProcessTime');

        console.log('âœ… æµå¼å“åº”éªŒè¯é€šè¿‡');
      }
    }, 15000);

    test('åº”è¯¥æ­£ç¡®å¤„ç†ä¸åŒçš„æ¨¡å‹è¯·æ±‚', async () => {
      const models = ['gpt-4o-mini', 'gpt-3.5-turbo'];

      for (const model of models) {
        const request = createTestRequest({
          query: `Test with ${model}`,
          model: model
        });

        const response = await POST(request);
        expect(response.status).toBe(200);
        
        console.log(`âœ… æ¨¡å‹ ${model} æµ‹è¯•é€šè¿‡`);
      }
    });

    test('åº”è¯¥åœ¨æµå¼å“åº”ä¸­åŒ…å«æ€§èƒ½æŒ‡æ ‡', async () => {
      const request = createTestRequest({
        query: 'Performance test query',
        model: 'gpt-4o-mini'
      });

      const response = await POST(request);
      const reader = response.body?.getReader();

      if (reader) {
        const chunks: string[] = [];
        let done = false;
        let foundPerformanceData = false;

        while (!done) {
          const { value, done: streamDone } = await reader.read();
          done = streamDone;

          if (value) {
            const chunk = new TextDecoder().decode(value);
            chunks.push(chunk);

            // æ£€æŸ¥æ˜¯å¦åŒ…å«æ€§èƒ½æ•°æ®
            if (chunk.includes('performance') && chunk.includes('serverProcessTime')) {
              foundPerformanceData = true;
            }
          }
        }

        expect(foundPerformanceData).toBe(true);
        console.log('âœ… æ€§èƒ½æŒ‡æ ‡åŒ…å«åœ¨å“åº”ä¸­');
      }
    });
  });

  describe('é”™è¯¯å¤„ç†é›†æˆæµ‹è¯•', () => {
    test('åº”è¯¥æ­£ç¡®å¤„ç†è®¤è¯å¤±è´¥', async () => {
      // æ¨¡æ‹Ÿè®¤è¯å¤±è´¥
      const { fastVerifyAuth } = require('../lib/auth');
      fastVerifyAuth.mockResolvedValueOnce({
        success: false,
        error: 'Invalid token'
      });

      const request = createTestRequest({
        query: 'Test query',
        model: 'gpt-4o-mini'
      });

      const response = await POST(request);
      expect(response.status).toBe(401);

      const data = await response.json();
      expect(data.error).toContain('æœªæˆæƒ');
      
      console.log('âœ… è®¤è¯å¤±è´¥å¤„ç†æ­£ç¡®');
    });

    test('åº”è¯¥æ­£ç¡®å¤„ç†ä½¿ç”¨é‡è¶…é™', async () => {
      // æ¨¡æ‹Ÿä½¿ç”¨é‡è¶…é™
      const { checkAndUpdateUsageUltraFast } = require('../lib/usage-ultra-fast');
      checkAndUpdateUsageUltraFast.mockResolvedValueOnce({
        success: false,
        canProceed: false,
        error: 'Usage limit exceeded'
      });

      const request = createTestRequest({
        query: 'Test query',
        model: 'gpt-4o-mini'
      });

      const response = await POST(request);
      expect(response.status).toBe(429);

      const data = await response.json();
      expect(data.error).toContain('ä½¿ç”¨é‡');
      
      console.log('âœ… ä½¿ç”¨é‡è¶…é™å¤„ç†æ­£ç¡®');
    });

    test('åº”è¯¥æ­£ç¡®å¤„ç† OpenAI API é”™è¯¯', async () => {
      // æ¨¡æ‹Ÿ OpenAI API é”™è¯¯
      const OpenAI = require('openai').default;
      const mockCreate = OpenAI.prototype.chat.completions.create;
      mockCreate.mockRejectedValueOnce(new Error('OpenAI API Error'));

      const request = createTestRequest({
        query: 'Test query',
        model: 'gpt-4o-mini'
      });

      const response = await POST(request);
      expect(response.status).toBe(500);

      const data = await response.json();
      expect(data.error).toBeDefined();
      
      console.log('âœ… OpenAI API é”™è¯¯å¤„ç†æ­£ç¡®');
    });
  });

  describe('æ€§èƒ½æµ‹è¯•', () => {
    test('æœåŠ¡å™¨å¤„ç†æ—¶é—´åº”è¯¥åœ¨åˆç†èŒƒå›´å†…', async () => {
      const startTime = Date.now();

      const request = createTestRequest({
        query: 'Performance test',
        model: 'gpt-4o-mini'
      });

      const response = await POST(request);
      const serverProcessTime = Date.now() - startTime;

      // æœåŠ¡å™¨å¤„ç†æ—¶é—´åº”è¯¥åœ¨ 2 ç§’å†…ï¼ˆåŒ…æ‹¬æ¨¡æ‹Ÿçš„ OpenAI å»¶è¿Ÿï¼‰
      expect(serverProcessTime).toBeLessThan(2000);
      expect(response.status).toBe(200);

      console.log(`ğŸ“Š æœåŠ¡å™¨å¤„ç†æ—¶é—´: ${serverProcessTime}ms`);
      console.log('âœ… æ€§èƒ½æµ‹è¯•é€šè¿‡');
    });

    test('å¹¶å‘è¯·æ±‚å¤„ç†', async () => {
      const concurrentRequests = 3;
      const requests = [];

      for (let i = 0; i < concurrentRequests; i++) {
        const request = createTestRequest({
          query: `Concurrent test ${i}`,
          model: 'gpt-4o-mini'
        });
        requests.push(POST(request));
      }

      const startTime = Date.now();
      const responses = await Promise.all(requests);
      const totalTime = Date.now() - startTime;

      // éªŒè¯æ‰€æœ‰è¯·æ±‚éƒ½æˆåŠŸ
      responses.forEach((response, index) => {
        expect(response.status).toBe(200);
        console.log(`âœ… å¹¶å‘è¯·æ±‚ ${index + 1} æˆåŠŸ`);
      });

      console.log(`ğŸ“Š ${concurrentRequests} ä¸ªå¹¶å‘è¯·æ±‚æ€»æ—¶é—´: ${totalTime}ms`);
      console.log('âœ… å¹¶å‘å¤„ç†æµ‹è¯•é€šè¿‡');
    });
  });

  describe('æµå¼å“åº”è¯¦ç»†æµ‹è¯•', () => {
    test('åº”è¯¥æŒ‰æ­£ç¡®é¡ºåºå‘é€æµå¼æ•°æ®', async () => {
      const request = createTestRequest({
        query: 'Stream order test',
        model: 'gpt-4o-mini'
      });

      const response = await POST(request);
      const reader = response.body?.getReader();

      if (reader) {
        const events: string[] = [];
        let done = false;

        while (!done) {
          const { value, done: streamDone } = await reader.read();
          done = streamDone;

          if (value) {
            const chunk = new TextDecoder().decode(value);
            const lines = chunk.split('\n').filter(line => line.trim());
            
            for (const line of lines) {
              if (line.startsWith('data:')) {
                try {
                  const data = JSON.parse(line.slice(5));
                  if (data.type) {
                    events.push(data.type);
                  }
                } catch (e) {
                  // å¿½ç•¥è§£æé”™è¯¯
                }
              }
            }
          }
        }

        console.log('ğŸ“¡ æ¥æ”¶åˆ°çš„äº‹ä»¶é¡ºåº:', events);

        // éªŒè¯äº‹ä»¶é¡ºåº
        expect(events).toContain('performance');
        expect(events.length).toBeGreaterThan(0);

        console.log('âœ… æµå¼æ•°æ®é¡ºåºæ­£ç¡®');
      }
    });
  });
});

describe('è¾¹ç•Œæ¡ä»¶æµ‹è¯•', () => {
  test('åº”è¯¥å¤„ç†æé•¿çš„æŸ¥è¯¢', async () => {
    const longQuery = 'a'.repeat(5000); // 5000 å­—ç¬¦çš„æŸ¥è¯¢
    
    const request = createTestRequest({
      query: longQuery,
      model: 'gpt-4o-mini'
    });

    const response = await POST(request);
    expect(response.status).toBe(200);
    
    console.log('âœ… é•¿æŸ¥è¯¢å¤„ç†æ­£ç¡®');
  });

  test('åº”è¯¥å¤„ç†ç‰¹æ®Šå­—ç¬¦', async () => {
    const specialQuery = 'ä½ å¥½ï¼è¿™æ˜¯ä¸€ä¸ªåŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æµ‹è¯•ï¼š@#$%^&*()_+{}|:"<>?[]\\;\',./ ğŸš€ğŸ‰';
    
    const request = createTestRequest({
      query: specialQuery,
      model: 'gpt-4o-mini'
    });

    const response = await POST(request);
    expect(response.status).toBe(200);
    
    console.log('âœ… ç‰¹æ®Šå­—ç¬¦å¤„ç†æ­£ç¡®');
  });
});
